{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5b065f9",
   "metadata": {},
   "source": [
    "## Equipo 48\n",
    "\n",
    "| Nombre | Matrícula |\n",
    "| ------ | --------- |\n",
    "| André Zaragoza  | A01797076 |\n",
    "| Héctor Santillán | A01633395 |\n",
    "| Pablo de Jesus González | A01321850 |\n",
    "| Delbert Custodio | A01795613 |\n",
    "| Abel Diaz | A00566705 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb815493",
   "metadata": {},
   "source": [
    "# Dataset a trabajar: Seoul Bike Sharing Demand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd647a9",
   "metadata": {},
   "source": [
    "El dataset conocido como `Seoul Bike Sharing Demand` es una serie de registros los cuales fueron recabados en Febrero de 2020. El dataset contiene 13 columnas y 8760 registros en su formato original.\n",
    "\n",
    "Las columnas o features que se encuentran en el dataset son los siguientes:\n",
    "\n",
    "| Feature | Tipo | Notas |\n",
    "| ------- | ---- | ----- |\n",
    "| Date    | Temporal | Contiene la fecha en que se llevó a cabo un registro. Su formato es DD-MM-YYYY. |\n",
    "| Rented Bike Count | Entero | Muestra la cantidad de bicicletas que se rentaron a cierta hora en cierta fecha. |\n",
    "| Hour    | Temporal | Es la hora del día en que se registraron la cantidad de bicicletas rentadas respecto a la hora anterior. |\n",
    "| Temperature(°C) | Continua | Es la temperatura en grados Celsius que se registró en cierta fecha y hora del ambiente. |\n",
    "| Humidity(%) | Entero | Es la humedad relativa del ambiente (en %) registrada en la fecha y hora del registro. |\n",
    "| Wind speed (m/s) | Continua | La velocidad del viento en m/s registrada en la fecha y hora correspondientes. |\n",
    "| Visibility (10m) | Entero | Visibilidad en factores de 10 metros. |\n",
    "| Dew point temperature(°C) | Continua | Es la temperatura en la cual el aire se satura de humedad. |\n",
    "| Solar Radiation (MJ/m²)  | Continua | Cantidad o medida de radiación solar absorbida por unidad de área. | \n",
    "| Rainfall(mm) | Continua | Cantidad de lluvia registrada en milimetros. |\n",
    "| Snowfall (cm) | Continua | Cantidad de nieve registrada, en milimetros. | \n",
    "| Seasons | Categorica, nominal. | La época o temporada del año. |\n",
    "| Holiday | Binaria o Booleana | Indica si la fecha registada es una festividad. |\n",
    "| Functioning Day | Binaria. | Indica si el servicio de renta de bicicletas operó o no en la fecha indicada. |\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Respecto al dataset modificado, podemos encontrar una columna extra:\n",
    "\n",
    "| Feature | Tipo | Notas |\n",
    "| ------- | ---- | ----- |\n",
    "| mixed_type_col | Desconocida | Debemos analizar la columna en nuestro EDA. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bada984",
   "metadata": {},
   "source": [
    "# Problemática a resolver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173b3c2f",
   "metadata": {},
   "source": [
    "Según la página de UCI sobre el dataset original, se introdujo la posibilidad de rentar bicicletas en distintas ciudades para mejorar la movilidad dentro de las zonas urbanas. Con esto, un aspecto importante es poder suplir la demanda de bicicletas que se puedan rentar a cualquier hora del día, ya que:\n",
    "\n",
    "- El esperar mucho tiempo para rentar una bicicleta puede causar que el uso de éstas se reduzca.\n",
    "- Utilizar una bicicleta para moverse dentro de una ciudad reduce el tráfico vehicular para evitar congestionamientos, por lo que es un indispensable cubrir la demanda de bicicletas que se necesiten durante el día y sobre todo a horas pico.\n",
    "\n",
    "Por lo anterior, el dataset produce una base sólida para trabajar un modelo de regresión que pueda predecir la demanda de bicicletas que se tendrá por cada hora del día. Esta predicción ayudará a que las autoridades puedan mantener una oferta de bicicletas acorde a las necesidades de la población, y a planificar de mejor manera la cantida de bicicletas a adquirir y dar mantenimiento.\n",
    "\n",
    "Por lo tanto, la variable a predecir para resolver la problemática es `Rented_Bike_Count`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5471b60a",
   "metadata": {},
   "source": [
    "# Inicialización y Carga de Datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67165894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado exitosamente. Las primeras 5 filas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Rented Bike Count</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Dew point temperature(°C)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Functioning Day</th>\n",
       "      <th>mixed_type_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/12/2017</td>\n",
       "      <td>254.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "      <td>876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/12/2017</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "      <td>798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/12/2017</td>\n",
       "      <td>173.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>-17.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/12/2017</td>\n",
       "      <td>107.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/12/2017</td>\n",
       "      <td>78.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>-18.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Rented Bike Count Hour Temperature(°C) Humidity(%)  \\\n",
       "0  01/12/2017             254.0  0.0           -5.2         37.0   \n",
       "1  01/12/2017             204.0  1.0            -5.5        38.0   \n",
       "2  01/12/2017             173.0  2.0            -6.0       39.0    \n",
       "3  01/12/2017            107.0   3.0            -6.2        40.0   \n",
       "4  01/12/2017              78.0  4.0            -6.0        36.0   \n",
       "\n",
       "  Wind speed (m/s) Visibility (10m) Dew point temperature(°C)  \\\n",
       "0             2.2            2000.0                     -17.6   \n",
       "1              0.8           2000.0                     -17.6   \n",
       "2              1.0           2000.0                     -17.7   \n",
       "3              0.9          2000.0                      -17.6   \n",
       "4              2.3           2000.0                     -18.6   \n",
       "\n",
       "  Solar Radiation (MJ/m2) Rainfall(mm) Snowfall (cm) Seasons     Holiday  \\\n",
       "0                     0.0          0.0           0.0  Winter  No Holiday   \n",
       "1                     0.0          0.0           0.0  Winter  No Holiday   \n",
       "2                     0.0          0.0           0.0  Winter  No Holiday   \n",
       "3                     0.0          0.0           0.0  Winter  No Holiday   \n",
       "4                     0.0          0.0           0.0  Winter  No Holiday   \n",
       "\n",
       "  Functioning Day mixed_type_col  \n",
       "0             Yes            876  \n",
       "1             Yes            798  \n",
       "2             Yes            231  \n",
       "3             Yes            bad  \n",
       "4             Yes            536  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Cargar el Dataset\n",
    "df = pd.read_csv('./csv/seoul_bike_sharing_modified.csv')\n",
    "print(\"Dataset cargado exitosamente. Las primeras 5 filas:\")\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ef7e86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas a trabajar:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "date                         object\n",
       "demanda                      object\n",
       "hour                         object\n",
       "temperature(°c)              object\n",
       "humidity(%)                  object\n",
       "wind_speed_(m/s)             object\n",
       "visibility_(10m)             object\n",
       "dew_point_temperature(°c)    object\n",
       "solar_radiation_(mj/m2)      object\n",
       "rainfall(mm)                 object\n",
       "snowfall_(cm)                object\n",
       "seasons                      object\n",
       "holiday                      object\n",
       "functioning_day              object\n",
       "mixed_type_col               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Renombrar y Estandarizar Columnas\n",
    "# Eliminaremos los espacios entre los nombres de los features para reemplazarlos por underscores (_)\n",
    "\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "df.rename(columns={'rented_bike_count': 'demanda'}, inplace=True)\n",
    "\n",
    "# Imprimimos las nuevas columnas\n",
    "print('Columnas a trabajar:\\n')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4d37c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8935"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca334bf",
   "metadata": {},
   "source": [
    "En este punto es posible darnos cuenta de que contamos con un dataset el cual:\n",
    "\n",
    "- Contiene \"ruido\" en las variables de tipo numérico.\n",
    "- Variablles o features que deberían ser binarios contienen valores extraños (`holiday` y `functioning_day` son un claro ejemplo de ésto)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23f0e34",
   "metadata": {},
   "source": [
    "# Limpieza de nuestro dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5578d1",
   "metadata": {},
   "source": [
    "### Para `date`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1fc8db",
   "metadata": {},
   "source": [
    "Notamos que algunos valores de `date` tienen espacios en blanco que podrían darnos problemas más adelante. Por lo que procedemos a hacer un strip de las fechas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0afcb928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_date_column(value_to_clean):\n",
    "    \n",
    "    if value_to_clean is None or value_to_clean == '':\n",
    "        return None\n",
    "    \n",
    "    cleaned = str(value_to_clean).strip()\n",
    "    \n",
    "    if cleaned.lower() == 'nan':\n",
    "        return None\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "df['date'] = df['date'].apply(clean_date_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb6e9ff",
   "metadata": {},
   "source": [
    "### Limpieza de `holiday`, `functioning_day` y `seasons`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99274169",
   "metadata": {},
   "source": [
    "Notamos que los valores válidos para estos features son los siguientes:\n",
    "\n",
    "- `Para holiday`: `No holiday` & `Holiday`.\n",
    "- `Para functioning_day`: `Yes` & `No`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c4e0150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos para `holiday`: ['no' 'yes']\n",
      "Valores únicos para `functioning_day`: ['yes' 'no']\n",
      "Valores únicos para `seasons`: ['winter' 'spring' None 'summer' 'autumn']\n"
     ]
    }
   ],
   "source": [
    "print( f\"Valores únicos para `holiday`: {df['holiday'].unique()}\" )\n",
    "print( f\"Valores únicos para `functioning_day`: {df['functioning_day'].unique()}\" )\n",
    "print( f\"Valores únicos para `seasons`: {df['seasons'].unique()}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429991ec",
   "metadata": {},
   "source": [
    "#### Para `holiday`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cb95c2",
   "metadata": {},
   "source": [
    "Por lo tanto, ahora procedemos a trabajar sobre `Holiday` para asegurarnos que los valores en nuestro dataset sean correctos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "074c712d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Al aplicar nuestra función de limpieza tenemos los siguientes valores únicos en `holiday`: ['no' None 'yes']\n"
     ]
    }
   ],
   "source": [
    "def correct_holiday_values( value_to_clean ):\n",
    "    \n",
    "    \n",
    "    if ( (value_to_clean == 'nan') or (value_to_clean is None ) or (value_to_clean == '')):\n",
    "        return None\n",
    "    else:\n",
    "        value_to_clean = str(value_to_clean).lower()\n",
    "        value_to_clean = value_to_clean.strip()\n",
    "    \n",
    "        if value_to_clean == 'holiday':\n",
    "            return 'yes'\n",
    "        elif value_to_clean == 'no holiday':\n",
    "            return 'no'\n",
    "        \n",
    "df['Holiday_or_not'] = df['holiday'].apply(correct_holiday_values)\n",
    "print( f\"Al aplicar nuestra función de limpieza tenemos los siguientes valores únicos en `holiday`: {df['Holiday_or_not'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "111ae22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copiamos los valores obtenidos para holiday y eliminamos la columna que usamos para limpiar esta data\n",
    "\n",
    "df['holiday'] = df['Holiday_or_not']\n",
    "df.drop(columns=['Holiday_or_not'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6de2e3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10/12/2017' '17/12/2017' '19/12/2017' '20/12/2017' '21/12/2017'\n",
      " '22/12/2017' '23/12/2017' '26/12/2017' '29/12/2017' '30/12/2017'\n",
      " '05/01/2018' '09/01/2018' '14/01/2018' '19/01/2018' '21/01/2018'\n",
      " '23/01/2018' '27/02/2018' '28/02/2018' '01/03/2018' '18/03/2018'\n",
      " '20/03/2018' '21/03/2018' '23/03/2018' '09/04/2018' '16/04/2018' None\n",
      " '26/04/2018' '27/04/2018' '02/05/2018' '06/05/2018' '19/05/2018'\n",
      " '20/05/2018' '22/05/2018' '23/05/2018' '27/05/2018' '11/06/2018'\n",
      " '12/06/2018' '18/06/2018' '19/06/2018' '25/06/2018' '08/07/2018'\n",
      " '11/07/2018' '13/07/2018' '24/07/2018' '25/07/2018' '30/07/2018'\n",
      " '31/07/2018' '03/08/2018' '13/08/2018' '22/08/2018' '31/08/2018'\n",
      " '02/09/2018' '05/09/2018' '14/09/2018' '20/09/2018' '22/09/2018'\n",
      " '23/09/2018' '30/09/2018' '05/10/2018' '15/10/2018' '27/10/2018'\n",
      " '28/10/2018' '31/10/2018' '02/11/2018' '06/11/2018' '12/11/2018'\n",
      " '13/11/2018' '14/11/2018' '22/11/2018' '23/11/2018' '25/11/2018'\n",
      " '30/11/2018' '15/11/2018' '28/04/2018']\n"
     ]
    }
   ],
   "source": [
    "# Ahora revisamos qué fechas tienen valores None en la columna de holiday para investigar si estos fueron días festivos en Seoul.\n",
    "\n",
    "print( df.loc[df['holiday'].isna(), 'date'].unique() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eae1d5",
   "metadata": {},
   "source": [
    "Y luego de una búsqueda rápida en internet, las siguientes fechas fueron festivas en Seoul:\n",
    "\n",
    "- 01/03/2018\n",
    "- 22/05/2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd694b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no', 'yes'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entonces, procedemos a cambiar los valores None por 'yes' o 'no' con base en la fecha de registro.\n",
    "# En este paso, existe un registro con fecha NaN que tomará el valor de 'no', pero esto podemos trabajarlo después.\n",
    "\n",
    "festive_dates = ['01/03/2018', '22/05/2018']\n",
    "\n",
    "df['holiday'] = [ \n",
    "                 'yes' if  (h is None and d in festive_dates)\n",
    "                 else 'no' if (h is None and d not in festive_dates)\n",
    "                 else h for d,h in zip(df['date'], df['holiday'])]\n",
    "\n",
    "df['holiday'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dfd7e0",
   "metadata": {},
   "source": [
    "#### Para `functioning_day`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b36f9dc",
   "metadata": {},
   "source": [
    "Al correr el código de abajo es posible notar que no se encontró algún valor None o vacío en la columna `functioning_day` al usar una función similar al procesamiento de `holiday`, por lo que en este paso procedemos solamente a modificar los valores de `functioning_day` según lo obtenido por nuestra función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e6b089d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Al aplicar nuestra función de limpieza tenemos los siguientes valores únicos en `functioning_day`: ['yes' 'no']\n"
     ]
    }
   ],
   "source": [
    "def correct_functioning_day_values( value_to_clean):\n",
    "    \n",
    "    if ( (value_to_clean == 'nan') or (value_to_clean is None ) or (value_to_clean == '')):\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        value_to_clean = str(value_to_clean).lower()\n",
    "        value_to_clean = value_to_clean.strip()\n",
    "    \n",
    "        if value_to_clean == 'yes':\n",
    "            return 'yes'\n",
    "        else:\n",
    "            return 'no'\n",
    "        \n",
    "df['functioning_day_or_not'] = df['functioning_day'].apply(correct_functioning_day_values)\n",
    "print( f\"Al aplicar nuestra función de limpieza tenemos los siguientes valores únicos en `functioning_day`: {df['functioning_day_or_not'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b4eeef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['yes', 'no'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['functioning_day'] = df['functioning_day_or_not']\n",
    "df.drop(columns=['functioning_day_or_not'], inplace=True)\n",
    "df['functioning_day'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1cd5b0",
   "metadata": {},
   "source": [
    "Y ahora procedemos a revisar la distribución de cada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adf120a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convertir 'date' al tipo datetime\n",
    "# df['date'] = pd.to_datetime(df['date'], format='%d/%m/%Y')\n",
    "\n",
    "# # Combinar fecha y hora en una sola columna para análisis de series de tiempo\n",
    "# df['datetime'] = df['date'] + pd.to_timedelta(df['hour'], unit='h')\n",
    "# df.set_index('datetime', inplace=True)\n",
    "# df.drop(['date', 'hour'], axis=1, inplace=True)\n",
    "\n",
    "# print(\"\\n--- DataFrame después de la conversión de tipos ---\")\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a79191",
   "metadata": {},
   "source": [
    "#### Para `seasons`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5aa04f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Winter', ' wINTER ', nan, ' NAN ', 'Spring', ' sPRING ', 'Summer',\n",
       "       ' sUMMER ', 'Autumn', ' aUTUMN '], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['seasons'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29bcf66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['winter', None, 'spring', 'summer', 'autumn'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def correct_season_values( value_to_clean):\n",
    "    \n",
    "    if ( (value_to_clean == 'nan') or (value_to_clean is None ) or (value_to_clean == '')):\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        value_to_clean = str(value_to_clean).strip().lower()\n",
    "        \n",
    "        if value_to_clean == 'nan':\n",
    "            return None\n",
    "        \n",
    "        return value_to_clean\n",
    "        \n",
    "df['seasons_corrected'] = df['seasons'].apply(correct_season_values)\n",
    "df['seasons_corrected'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40967d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores unicos para `seasons` luego de aplicar la corrección: ['winter' None 'spring' 'summer' 'autumn']\n"
     ]
    }
   ],
   "source": [
    "df['seasons'] = df['seasons_corrected']\n",
    "df.drop(columns=['seasons_corrected'], inplace=True)\n",
    "\n",
    "print(f\"Valores unicos para `seasons` luego de aplicar la corrección: {df['seasons'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47e2c288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['06/12/2017' '14/12/2017' '16/12/2017' '27/12/2017' '01/01/2018'\n",
      " '12/01/2018' '14/01/2018' '17/01/2018' '18/01/2018' '21/01/2018'\n",
      " '27/01/2018' '30/01/2018' '05/02/2018' '09/02/2018' '19/02/2018'\n",
      " '20/02/2018' '25/02/2018' '26/02/2018' '28/02/2018' None '02/03/2018'\n",
      " '05/03/2018' '08/03/2018' '22/03/2018' '26/03/2018' '27/03/2018'\n",
      " '29/03/2018' '02/04/2018' '04/04/2018' '14/04/2018' '16/04/2018'\n",
      " '18/04/2018' '21/04/2018' '22/04/2018' '11/05/2018' '24/05/2018'\n",
      " '10/06/2018' '18/06/2018' '25/06/2018' '28/06/2018' '29/06/2018'\n",
      " '07/07/2018' '08/07/2018' '16/07/2018' '18/07/2018' '19/07/2018'\n",
      " '22/07/2018' '25/07/2018' '31/07/2018' '01/08/2018' '02/08/2018'\n",
      " '07/08/2018' '10/08/2018' '22/08/2018' '29/08/2018' '02/09/2018'\n",
      " '03/09/2018' '11/09/2018' '13/09/2018' '17/09/2018' '18/09/2018'\n",
      " '13/10/2018' '14/10/2018' '17/10/2018' '24/10/2018' '04/11/2018'\n",
      " '08/11/2018' '10/11/2018' '13/11/2018' '19/11/2018' '20/11/2018'\n",
      " '23/11/2018' '29/11/2018' '30/11/2018' '07/05/2018' '04/08/2018']\n"
     ]
    }
   ],
   "source": [
    "# Verificamos las fechas en donde tenemos None\n",
    "\n",
    "print( df.loc[df['seasons'].isna(), 'date'].unique() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856407ae",
   "metadata": {},
   "source": [
    "Y luego de una búsqueda rápida en Internet obtenemos cuales fechas pertenecen al invierno, verano, otoño y primavera en Seoul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5912c03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['winter', 'spring', None, 'summer', 'autumn'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winter_dates = [\n",
    "'06/12/2017', '14/12/2017', '16/12/2017', '27/12/2017', '01/01/2018',\n",
    "'12/01/2018', '14/01/2018', '17/01/2018', '18/01/2018', '21/01/2018',\n",
    "'27/01/2018', '30/01/2018', '05/02/2018', '09/02/2018', '19/02/2018',\n",
    "'20/02/2018', '25/02/2018', '26/02/2018', '28/02/2018'\n",
    "]\n",
    "\n",
    "spring_dates = [\n",
    "'02/03/2018', '05/03/2018', '08/03/2018', '22/03/2018', '26/03/2018',\n",
    "'27/03/2018', '29/03/2018', '02/04/2018', '04/04/2018', '14/04/2018',\n",
    "'16/04/2018', '18/04/2018', '21/04/2018', '22/04/2018', '07/05/2018',\n",
    "'11/05/2018', '24/05/2018'\n",
    "]\n",
    "\n",
    "summer_dates = [\n",
    "'10/06/2018', '18/06/2018', '25/06/2018', '28/06/2018', '29/06/2018',\n",
    "'07/07/2018', '08/07/2018', '16/07/2018', '18/07/2018', '19/07/2018',\n",
    "'22/07/2018', '25/07/2018', '31/07/2018', '01/08/2018', '02/08/2018',\n",
    "'04/08/2018', '07/08/2018', '10/08/2018', '22/08/2018', '29/08/2018'\n",
    "]\n",
    "\n",
    "autumn_dates = [\n",
    "'02/09/2018', '03/09/2018', '11/09/2018', '13/09/2018', '17/09/2018',\n",
    "'18/09/2018', '13/10/2018', '14/10/2018', '17/10/2018', '24/10/2018',\n",
    "'04/11/2018', '08/11/2018', '10/11/2018', '13/11/2018', '19/11/2018',\n",
    "'20/11/2018', '23/11/2018', '29/11/2018', '30/11/2018'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "df['seasons'] = [ \n",
    "                      'winter' if (s is None and d in winter_dates)\n",
    "                 else 'spring' if (s is None and d in spring_dates)\n",
    "                 else 'summer' if (s is None and d in summer_dates)\n",
    "                 else 'autumn' if (s is None and d in autumn_dates)\n",
    "                 else s for d,s in zip(df['date'], df['seasons'])]\n",
    "\n",
    "df['seasons'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27cf4d7",
   "metadata": {},
   "source": [
    "Y verificamos que solamente las columnas que tengan `None` en `Date` deben aparecer con valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4666de8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None]\n"
     ]
    }
   ],
   "source": [
    "print( df.loc[df['seasons'].isna(), 'date'].unique() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933dc3b2",
   "metadata": {},
   "source": [
    "### Variables numéricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c69a44f",
   "metadata": {},
   "source": [
    "#### Para `Rented_bikes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1879e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def check_if_numeric_value ( value_to_check):\n",
    "    \n",
    "    try:\n",
    "        float(value_to_check)\n",
    "        return float(value_to_check)\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "    \n",
    "df['clean_demanda'] = df['demanda'].apply(check_if_numeric_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c7255cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_demanda\n",
       "False    8799\n",
       "True      136\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_demanda'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01b7368",
   "metadata": {},
   "source": [
    "Al revisar la cantidad de valores nulos o vacíos en la variable objetivo `demanda`, es posible calcular que el 1.52% de los registros no tiene un valor válido. Entonces, hemos decidido eliminar estos registros ya que:\n",
    "\n",
    "- Al ser `demanda` la variable objetivo o a predecir, el imputar o agregar valores podría introducir sesgos bastante fuertes en nuestro modelo.\n",
    "\n",
    "Por lo anterior, decidimos utilizar solo información real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ea357fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_demanda\n",
       "False    8799\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=['clean_demanda'], inplace=True)\n",
    "df['clean_demanda'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c39735",
   "metadata": {},
   "source": [
    "### Para `mixed_type_col`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aae37ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['mixed_type_col'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b7900f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mixed_type_col\n",
       "bad        897\n",
       "unknown    890\n",
       "583         16\n",
       "11          16\n",
       "161         15\n",
       "183         14\n",
       "972         14\n",
       "603         13\n",
       "516         13\n",
       "950         13\n",
       "241         13\n",
       "948         12\n",
       "86          12\n",
       "679         12\n",
       "713         12\n",
       "333         12\n",
       "168         12\n",
       "181         12\n",
       "980         12\n",
       "219         12\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mixed_type_col'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "baa3fe1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(9.512444595976815)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mixed_type_col'].isna().sum() / len(df) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe4dbab",
   "metadata": {},
   "source": [
    "Al revisar el Top 20 de valores, notamos que no existe alguna ventaja en mantener la columna `mixed_type_column`. Nuestros criterios son los siguientes:\n",
    "\n",
    "- El 9.5% de los datos es vacío o nulo.\n",
    "- El top 20 de valores únicos muestra una mezcla de valores categóricos y numéricos.\n",
    "- El nombre de la columna no nos da información extra para comprender lo que quiere decir.\n",
    "- No fue posible hallar alguna documentación sobre cómo se creó esta columna en el sitio oficial de UCI para el dataset en cuestión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbac3d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                                   object\n",
       "demanda                                object\n",
       "hour                                   object\n",
       "temperature(°c)                        object\n",
       "humidity(%)                            object\n",
       "wind_speed_(m/s)                       object\n",
       "visibility_(10m)                       object\n",
       "dew_point_temperature(°c)              object\n",
       "solar_radiation_(mj/m2)                object\n",
       "rainfall(mm)                           object\n",
       "snowfall_(cm)                          object\n",
       "seasons                                object\n",
       "holiday                                object\n",
       "functioning_day                        object\n",
       "rented_bike_count_is_numeric_value       bool\n",
       "clean_demanda                         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['mixed_type_col'], inplace= True)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec12c5f",
   "metadata": {},
   "source": [
    "### Para `temperature`, `humidity`, `wind_speed`, `solar_radiation`, `rainfall`, `snowfall`, `dew_point` y `visibility_(10m)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d20c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_cols = [\n",
    "    'temperature(°c)', \n",
    "    'humidity(%)', \n",
    "    'wind_speed_(m/s)', \n",
    "    'visibility_(10m)',\n",
    "    'dew_point_temperature(°c)', \n",
    "    'solar_radiation_(mj/m2)',\n",
    "    'rainfall(mm) ', \n",
    "    'snowfall_(cm)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd702dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                                  0.943289\n",
       "demanda                               0.000000\n",
       "hour                                  1.272872\n",
       "temperature(°c)                       1.011479\n",
       "humidity(%)                           1.091033\n",
       "wind_speed_(m/s)                      1.386521\n",
       "visibility_(10m)                      1.022844\n",
       "dew_point_temperature(°c)             1.125128\n",
       "solar_radiation_(mj/m2)               0.977384\n",
       "rainfall(mm)                          0.897829\n",
       "snowfall_(cm)                         1.113763\n",
       "seasons                               0.034095\n",
       "holiday                               0.000000\n",
       "functioning_day                       0.000000\n",
       "rented_bike_count_is_numeric_value    0.000000\n",
       "clean_demanda                         0.000000\n",
       "clean_temp                            1.318332\n",
       "clean_hum                             1.466076\n",
       "clean_wspeed                          1.784294\n",
       "clean_sradiation                      1.238777\n",
       "clean_rnfll                           1.295602\n",
       "clean_snwfll                          1.420616\n",
       "clean_dwtemp                          1.466076\n",
       "dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum() / len(df) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e72cb2",
   "metadata": {},
   "source": [
    "Notamos que el porcentaje de valores nulos en cada una de éstas variables es bajo (no se supera el 5% de los datos), por lo que tenemos algunas estrategias para rellenar esta data:\n",
    "\n",
    "- Utilizar una medida de tendencia central como la `media` o `mediana`. Esto ignora los patrones climatológicos, por lo que no es la mejor estrategia.\n",
    "- Buscar una manera de tomar en cuenta la hora del día y la temporada (`season`) para calcular el promedio.\n",
    "- Usar alguna técnica como Forward-Fill o Backward-Fill, lo que en algunos estudios se recomienda para data que se encuentra ordenada con base al tiempo.\n",
    "\n",
    "\n",
    "Por lo anterior, hemos decidido utilizar forwardfill y backwardfill en estas variables, ya que:\n",
    "\n",
    "- Las mismas dependen del mes, día y hora.\n",
    "- Están correlacionadas fuertemente con la fecha (ejemplo: en Seoul siempre llueve en invierno, llueve o no llueve en verano, etc.)\n",
    "\n",
    "\n",
    "Pero antes de trabajar con los valores vacíos, debemos asegurarnos de que estas columnas no contengan alguna mezcla de tipos de datos (texto y numeros, por ejemplo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3890a8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros NaN de la columna: temperature(°c)\n",
      "False    8683\n",
      "True      116\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Cantidad de registros NaN de la columna: humidity(%)\n",
      "False    8670\n",
      "True      129\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Cantidad de registros NaN de la columna: wind_speed_(m/s)\n",
      "False    8670\n",
      "True      129\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Cantidad de registros NaN de la columna: visibility_(10m)\n",
      "False    8685\n",
      "True      114\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Cantidad de registros NaN de la columna: dew_point_temperature(°c)\n",
      "False    8674\n",
      "True      125\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Cantidad de registros NaN de la columna: solar_radiation_(mj/m2)\n",
      "False    8690\n",
      "True      109\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Cantidad de registros NaN de la columna: rainfall(mm) \n",
      "False    8642\n",
      "True      157\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Cantidad de registros NaN de la columna: snowfall_(cm)\n",
      "False    8669\n",
      "True      130\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Primero chequearemos cuales registros no cuentan con un valor válido en alguna de estas columnas, y  colocaremos NaN en donde no se encuentra algún valor\n",
    "# numérico.\n",
    "\n",
    "for col in weather_cols:\n",
    "    df[ f\"{col}\" ] = df[ f\"{col}\"].apply(check_if_numeric_value)\n",
    "    \n",
    "for col in weather_cols:\n",
    "    print( f\"Cantidad de registros NaN de la columna: {df[f\"{col}\"].isna().value_counts()}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56081387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros NaN de la columna: temperature(°c)\n",
      "False    8799\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Cantidad de registros NaN de la columna: humidity(%)\n",
      "False    8799\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Cantidad de registros NaN de la columna: wind_speed_(m/s)\n",
      "False    8799\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Cantidad de registros NaN de la columna: visibility_(10m)\n",
      "False    8799\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Cantidad de registros NaN de la columna: dew_point_temperature(°c)\n",
      "False    8799\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Cantidad de registros NaN de la columna: solar_radiation_(mj/m2)\n",
      "False    8799\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Cantidad de registros NaN de la columna: rainfall(mm) \n",
      "False    8799\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Cantidad de registros NaN de la columna: snowfall_(cm)\n",
      "False    8799\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30162/1708373508.py:5: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[f\"{col}\"] = df[f\"{col}\"].fillna(method= 'ffill')\n",
      "/tmp/ipykernel_30162/1708373508.py:6: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[f\"{col}\"] = df[f\"{col}\"].fillna(method= 'bfill')\n"
     ]
    }
   ],
   "source": [
    "# Y ahora trabajamos en usar un ForwarFill seguido de un backwardfill\n",
    "for col in weather_cols:\n",
    "    \n",
    "    df[f\"{col}\"] = df[f\"{col}\"].fillna(method= 'ffill')\n",
    "    df[f\"{col}\"] = df[f\"{col}\"].fillna(method= 'bfill')\n",
    "\n",
    "for col in weather_cols:\n",
    "    print( f\"Cantidad de registros NaN de la columna: {df[f\"{col}\"].isna().value_counts()}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee60ed61",
   "metadata": {},
   "source": [
    "Por último, notamos que ya no contamos con valores NaN en nuestras columnas de clima luego de usar `ffill` y `bfill` en nuestro dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8987ea44",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5e80d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Información General y Tipos de Datos ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8935 entries, 0 to 8934\n",
      "Data columns (total 15 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   date                       8857 non-null   object\n",
      " 1   demanda                    8829 non-null   object\n",
      " 2   hour                       8820 non-null   object\n",
      " 3   temperature(°c)            8846 non-null   object\n",
      " 4   humidity(%)                8837 non-null   object\n",
      " 5   wind_speed_(m/s)           8812 non-null   object\n",
      " 6   visibility_(10m)           8843 non-null   object\n",
      " 7   dew_point_temperature(°c)  8833 non-null   object\n",
      " 8   solar_radiation_(mj/m2)    8846 non-null   object\n",
      " 9   rainfall(mm)               8855 non-null   object\n",
      " 10  snowfall_(cm)              8834 non-null   object\n",
      " 11  seasons                    8856 non-null   object\n",
      " 12  holiday                    8857 non-null   object\n",
      " 13  functioning_day            8838 non-null   object\n",
      " 14  mixed_type_col             8085 non-null   object\n",
      "dtypes: object(15)\n",
      "memory usage: 1.0+ MB\n",
      "\n",
      "\n",
      "--- Estadísticas Descriptivas de Variables Numéricas ---\n",
      "                          count unique         top  freq\n",
      "date                       8857    628  15/11/2018    26\n",
      "demanda                    8829   2542         0.0   279\n",
      "hour                       8820    140         2.0   353\n",
      "temperature(°c)            8846    894        19.1    39\n",
      "humidity(%)                8837    272        53.0   168\n",
      "wind_speed_(m/s)           8812    207         1.1   389\n",
      "visibility_(10m)           8843   2102      2000.0  2139\n",
      "dew_point_temperature(°c)  8833    920         0.0    57\n",
      "solar_radiation_(mj/m2)    8846    581         0.0  4096\n",
      "rainfall(mm)               8855    115         0.0  7838\n",
      "snowfall_(cm)              8834    112         0.0  7895\n",
      "seasons                    8856      9      Summer  2133\n",
      "holiday                    8857      5  No Holiday  7997\n",
      "functioning_day            8838      5         Yes  8105\n",
      "mixed_type_col             8085   1001         bad   910\n",
      "\n",
      "--- Conteo de Valores Únicos en Variables Categóricas/Discretas ---\n",
      "seasons\n",
      "Summer      2133\n",
      "Spring      2112\n",
      "Autumn      2101\n",
      "Winter      2090\n",
      " sPRING      122\n",
      " aUTUMN      103\n",
      " sUMMER       96\n",
      " wINTER       90\n",
      " NAN           9\n",
      "Name: count, dtype: int64\n",
      "holiday\n",
      "No Holiday      7997\n",
      " nO hOLIDAY      419\n",
      "Holiday          411\n",
      " hOLIDAY          25\n",
      " NAN               5\n",
      "Name: count, dtype: int64\n",
      "functioning_day\n",
      "Yes      8105\n",
      " yES      428\n",
      "No        284\n",
      " nO        15\n",
      " NAN        6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Información General y Tipos de Datos ---\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\\n--- Estadísticas Descriptivas de Variables Numéricas ---\")\n",
    "print(df.describe().T)\n",
    "\n",
    "print(\"\\n--- Conteo de Valores Únicos en Variables Categóricas/Discretas ---\")\n",
    "print(df['seasons'].value_counts())\n",
    "print(df['holiday'].value_counts())\n",
    "print(df['functioning_day'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8abe0f4",
   "metadata": {},
   "source": [
    "# Limpieza y Transformación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e482a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DataFrame después de la conversión de tipos ---\n",
      "                     demanda  temperature(°c)  humidity(%)  wind_speed_(m/s)  \\\n",
      "datetime                                                                       \n",
      "2017-12-01 00:00:00      254             -5.2           37               2.2   \n",
      "2017-12-01 01:00:00      204             -5.5           38               0.8   \n",
      "2017-12-01 02:00:00      173             -6.0           39               1.0   \n",
      "2017-12-01 03:00:00      107             -6.2           40               0.9   \n",
      "2017-12-01 04:00:00       78             -6.0           36               2.3   \n",
      "\n",
      "                     visibility_(10m)  dew_point_temperature(°c)  \\\n",
      "datetime                                                           \n",
      "2017-12-01 00:00:00              2000                      -17.6   \n",
      "2017-12-01 01:00:00              2000                      -17.6   \n",
      "2017-12-01 02:00:00              2000                      -17.7   \n",
      "2017-12-01 03:00:00              2000                      -17.6   \n",
      "2017-12-01 04:00:00              2000                      -18.6   \n",
      "\n",
      "                     solar_radiation_(mj/m2)  rainfall(mm)  snowfall_(cm)  \\\n",
      "datetime                                                                    \n",
      "2017-12-01 00:00:00                      0.0           0.0            0.0   \n",
      "2017-12-01 01:00:00                      0.0           0.0            0.0   \n",
      "2017-12-01 02:00:00                      0.0           0.0            0.0   \n",
      "2017-12-01 03:00:00                      0.0           0.0            0.0   \n",
      "2017-12-01 04:00:00                      0.0           0.0            0.0   \n",
      "\n",
      "                    seasons     holiday functioning_day  \n",
      "datetime                                                 \n",
      "2017-12-01 00:00:00  Winter  No Holiday             Yes  \n",
      "2017-12-01 01:00:00  Winter  No Holiday             Yes  \n",
      "2017-12-01 02:00:00  Winter  No Holiday             Yes  \n",
      "2017-12-01 03:00:00  Winter  No Holiday             Yes  \n",
      "2017-12-01 04:00:00  Winter  No Holiday             Yes  \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc92eac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Conteo de Valores Nulos por Columna ---\n",
      "demanda                      0\n",
      "temperature(°c)              0\n",
      "humidity(%)                  0\n",
      "wind_speed_(m/s)             0\n",
      "visibility_(10m)             0\n",
      "dew_point_temperature(°c)    0\n",
      "solar_radiation_(mj/m2)      0\n",
      "rainfall(mm)                 0\n",
      "snowfall_(cm)                0\n",
      "seasons                      0\n",
      "holiday                      0\n",
      "functioning_day              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. Verificar Nulos (Métricas)\n",
    "print(\"\\n--- Conteo de Valores Nulos por Columna ---\")\n",
    "print(df.isnull().sum())\n",
    "# Si aparecen nulos, la acción recomendada (imputación con media/mediana o eliminación) depende de la cantidad.\n",
    "\n",
    "# 2. Manejo de Inconsistencias\n",
    "# Las variables 'functioning_day' deben ser binarias (Yes/No o Fun/NoFunc)\n",
    "# En este dataset son 'Yes' y 'No', lo cual es consistente.\n",
    "\n",
    "# Convertir 'functioning_day' y 'holiday' a numérico (0 y 1)\n",
    "df['functioning_day'] = df['functioning_day'].map({'Yes': 1, 'No': 0})\n",
    "df['holiday'] = df['holiday'].map({'No Holiday': 0, 'Holiday': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76cbd705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Detección de Outliers en Demanda ---\n",
      "Límite Superior (1.5*IQR): 2377\n",
      "Número de outliers detectados: 158\n",
      "Máximo de Demanda (Original): 3556\n",
      "Máximo de Demanda (Limpia): 2377\n"
     ]
    }
   ],
   "source": [
    "# Aplicar la detección de outliers en la variable 'demanda'\n",
    "Q1 = df['demanda'].quantile(0.25)\n",
    "Q3 = df['demanda'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "limite_superior = Q3 + 1.5 * IQR\n",
    "\n",
    "# 1. Conteo de Outliers\n",
    "outliers_count = df[df['demanda'] > limite_superior].shape[0]\n",
    "print(f\"\\n--- Detección de Outliers en Demanda ---\")\n",
    "print(f\"Límite Superior (1.5*IQR): {limite_superior:.0f}\")\n",
    "print(f\"Número de outliers detectados: {outliers_count}\")\n",
    "\n",
    "# 2. Opción de Limpieza (Imputación por tope o 'Capping')\n",
    "# En lugar de eliminar, reemplazamos los outliers con el límite superior (Capping).\n",
    "# Esto es común en modelos de regresión para mantener el tamaño del dataset.\n",
    "df['demanda_limpia'] = np.where(\n",
    "    df['demanda'] > limite_superior,\n",
    "    limite_superior,\n",
    "    df['demanda']\n",
    ")\n",
    "\n",
    "# Comparación del máximo antes y después\n",
    "print(f\"Máximo de Demanda (Original): {df['demanda'].max()}\")\n",
    "print(f\"Máximo de Demanda (Limpia): {df['demanda_limpia'].max():.0f}\")\n",
    "\n",
    "# Se puede eliminar la columna original 'demanda' si solo se usará la 'demanda_limpia'\n",
    "df.drop('demanda', axis=1, inplace=True)\n",
    "df.rename(columns={'demanda_limpia': 'demanda'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72037468",
   "metadata": {},
   "source": [
    "### Buscamos algunas relaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef9cd1b",
   "metadata": {},
   "source": [
    "# Transformaciones Finales (Feature Engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65f24f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DataFrame después del One-Hot Encoding de 'seasons' ---\n",
      "                     temperature(°c)  humidity(%)  wind_speed_(m/s)  \\\n",
      "datetime                                                              \n",
      "2017-12-01 00:00:00             -5.2           37               2.2   \n",
      "2017-12-01 01:00:00             -5.5           38               0.8   \n",
      "2017-12-01 02:00:00             -6.0           39               1.0   \n",
      "2017-12-01 03:00:00             -6.2           40               0.9   \n",
      "2017-12-01 04:00:00             -6.0           36               2.3   \n",
      "\n",
      "                     visibility_(10m)  dew_point_temperature(°c)  \\\n",
      "datetime                                                           \n",
      "2017-12-01 00:00:00              2000                      -17.6   \n",
      "2017-12-01 01:00:00              2000                      -17.6   \n",
      "2017-12-01 02:00:00              2000                      -17.7   \n",
      "2017-12-01 03:00:00              2000                      -17.6   \n",
      "2017-12-01 04:00:00              2000                      -18.6   \n",
      "\n",
      "                     solar_radiation_(mj/m2)  rainfall(mm)  snowfall_(cm)  \\\n",
      "datetime                                                                    \n",
      "2017-12-01 00:00:00                      0.0           0.0            0.0   \n",
      "2017-12-01 01:00:00                      0.0           0.0            0.0   \n",
      "2017-12-01 02:00:00                      0.0           0.0            0.0   \n",
      "2017-12-01 03:00:00                      0.0           0.0            0.0   \n",
      "2017-12-01 04:00:00                      0.0           0.0            0.0   \n",
      "\n",
      "                     holiday  functioning_day  demanda  season_Autumn  \\\n",
      "datetime                                                                \n",
      "2017-12-01 00:00:00        0                1    254.0          False   \n",
      "2017-12-01 01:00:00        0                1    204.0          False   \n",
      "2017-12-01 02:00:00        0                1    173.0          False   \n",
      "2017-12-01 03:00:00        0                1    107.0          False   \n",
      "2017-12-01 04:00:00        0                1     78.0          False   \n",
      "\n",
      "                     season_Spring  season_Summer  season_Winter  \n",
      "datetime                                                          \n",
      "2017-12-01 00:00:00          False          False           True  \n",
      "2017-12-01 01:00:00          False          False           True  \n",
      "2017-12-01 02:00:00          False          False           True  \n",
      "2017-12-01 03:00:00          False          False           True  \n",
      "2017-12-01 04:00:00          False          False           True  \n"
     ]
    }
   ],
   "source": [
    "# Aplicar One-Hot Encoding a la variable 'seasons'\n",
    "df_encoded = pd.get_dummies(df, columns=['seasons'], prefix='season')\n",
    "\n",
    "print(\"\\n--- DataFrame después del One-Hot Encoding de 'seasons' ---\")\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "293b03bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DataFrame después del Feature Engineering ---\n",
      "                     temperature(°c)  humidity(%)  wind_speed_(m/s)  \\\n",
      "datetime                                                              \n",
      "2017-12-01 00:00:00             -5.2           37               2.2   \n",
      "2017-12-01 01:00:00             -5.5           38               0.8   \n",
      "2017-12-01 02:00:00             -6.0           39               1.0   \n",
      "2017-12-01 03:00:00             -6.2           40               0.9   \n",
      "2017-12-01 04:00:00             -6.0           36               2.3   \n",
      "\n",
      "                     visibility_(10m)  dew_point_temperature(°c)  \\\n",
      "datetime                                                           \n",
      "2017-12-01 00:00:00              2000                      -17.6   \n",
      "2017-12-01 01:00:00              2000                      -17.6   \n",
      "2017-12-01 02:00:00              2000                      -17.7   \n",
      "2017-12-01 03:00:00              2000                      -17.6   \n",
      "2017-12-01 04:00:00              2000                      -18.6   \n",
      "\n",
      "                     solar_radiation_(mj/m2)  rainfall(mm)  snowfall_(cm)  \\\n",
      "datetime                                                                    \n",
      "2017-12-01 00:00:00                      0.0           0.0            0.0   \n",
      "2017-12-01 01:00:00                      0.0           0.0            0.0   \n",
      "2017-12-01 02:00:00                      0.0           0.0            0.0   \n",
      "2017-12-01 03:00:00                      0.0           0.0            0.0   \n",
      "2017-12-01 04:00:00                      0.0           0.0            0.0   \n",
      "\n",
      "                     holiday  functioning_day  demanda  season_Autumn  \\\n",
      "datetime                                                                \n",
      "2017-12-01 00:00:00        0                1    254.0          False   \n",
      "2017-12-01 01:00:00        0                1    204.0          False   \n",
      "2017-12-01 02:00:00        0                1    173.0          False   \n",
      "2017-12-01 03:00:00        0                1    107.0          False   \n",
      "2017-12-01 04:00:00        0                1     78.0          False   \n",
      "\n",
      "                     season_Spring  season_Summer  season_Winter  month  \\\n",
      "datetime                                                                  \n",
      "2017-12-01 00:00:00          False          False           True     12   \n",
      "2017-12-01 01:00:00          False          False           True     12   \n",
      "2017-12-01 02:00:00          False          False           True     12   \n",
      "2017-12-01 03:00:00          False          False           True     12   \n",
      "2017-12-01 04:00:00          False          False           True     12   \n",
      "\n",
      "                     day_of_week  is_weekend  \n",
      "datetime                                      \n",
      "2017-12-01 00:00:00            4           0  \n",
      "2017-12-01 01:00:00            4           0  \n",
      "2017-12-01 02:00:00            4           0  \n",
      "2017-12-01 03:00:00            4           0  \n",
      "2017-12-01 04:00:00            4           0  \n"
     ]
    }
   ],
   "source": [
    "# Crear variables adicionales de tiempo\n",
    "df_encoded['month'] = df_encoded.index.month\n",
    "df_encoded['day_of_week'] = df_encoded.index.day_of_week # 0=Lunes, 6=Domingo\n",
    "df_encoded['is_weekend'] = df_encoded['day_of_week'].apply(lambda x: 1 if x >= 5 else 0) # Sábado y Domingo\n",
    "\n",
    "print(\"\\n--- DataFrame después del Feature Engineering ---\")\n",
    "print(df_encoded.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLOps (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
